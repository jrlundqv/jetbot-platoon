{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-catch",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "from datetime import datetime  # For timestamps\n",
    "import time  # Additional import that might be useful for delays\n",
    "import numpy as np\n",
    "from jetbot import Robot, Camera\n",
    "import pyzbar.pyzbar as pyzbar\n",
    "from pyzbar.pyzbar import decode\n",
    "\n",
    "\n",
    "class LineDetector:\n",
    "    def __init__(self, camera, width=224, height=224, save_dir='images_collection' ):\n",
    "        self.camera = camera\n",
    "        # Just if you want to use camera direct here, will be set from outside\n",
    "        #self.camera = Camera.instance(width=width, height=height)\n",
    "        self.image_height = height\n",
    "        self.image_width = width\n",
    "        # save images if needed\n",
    "        self.save_dir = save_dir\n",
    "        \n",
    "        # if direction does not exist, create direction here\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "            os.makedirs(os.path.join(save_dir, 'original'))\n",
    "            os.makedirs(os.path.join(save_dir, 'processed'))\n",
    "            \n",
    "    def preprocess_image_qrcode(self,image):\n",
    "        # Resize the image for better detection\n",
    "        resized_image = cv2.resize(image, None, fx=2, fy=2, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        # Convert to grayscale\n",
    "        gray_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Apply a sharpening kernel\n",
    "        kernel = np.array([[0, -1, 0],\n",
    "                           [-1, 5, -1],\n",
    "                           [0, -1, 0]])\n",
    "        sharpened_image = cv2.filter2D(gray_image, -1, kernel)\n",
    "\n",
    "        # Apply adaptive histogram equalization\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        enhanced_image = clahe.apply(sharpened_image)\n",
    "\n",
    "        return enhanced_image\n",
    "    \n",
    "    def detect_large_blue_rectangle(self, debug=False):\n",
    "        \"\"\"\n",
    "        Detects the largest blue rectangle in the camera feed.\n",
    "\n",
    "        Parameters:\n",
    "        camera_feed (numpy.ndarray): Input image frame from the camera.\n",
    "\n",
    "        Returns:\n",
    "        tuple: (boolean, center_x)\n",
    "            - boolean: True if a large blue rectangle (>detection_threshold of image) is detected, False otherwise.\n",
    "            - center_x: The x-coordinate of the center of the largest rectangle if detected, None otherwise.\n",
    "        \"\"\"\n",
    "        # Define the lower and upper bounds for the color blue in HSV\n",
    "        lower_blue = np.array([100, 80, 50])\n",
    "        upper_blue = np.array([140, 255, 255])\n",
    "\n",
    "        # Convert the image to HSV color space\n",
    "        hsv_image = cv2.cvtColor(self.camera.value, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        # Create a mask for blue color\n",
    "        mask = cv2.inRange(hsv_image, lower_blue, upper_blue)\n",
    "\n",
    "        # Find contours in the blue mask\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Initialize variables to store the largest rectangle's properties\n",
    "        largest_area = 0\n",
    "        largest_center_x = None\n",
    "        image_area = 50176\n",
    "        detection_threshold = 0.01\n",
    "        \n",
    "        annotated_image = self.camera.value.copy()\n",
    "\n",
    "        for contour in contours:\n",
    "            # Approximate the contour to a polygon and find its bounding rectangle\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            area = w * h\n",
    "\n",
    "            # Check if the current rectangle is the largest and blue\n",
    "            if area > largest_area:\n",
    "                largest_area = area\n",
    "                largest_center_x = x + w // 2\n",
    "                cv2.rectangle(annotated_image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                \n",
    "        if debug:\n",
    "            # Display the original feed, mask, and annotated image\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.title(\"Camera Feed\")\n",
    "            plt.imshow(cv2.cvtColor(self.camera.value, cv2.COLOR_BGR2RGB))\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.title(\"Blue Mask\")\n",
    "            plt.imshow(mask, cmap=\"gray\")\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.title(\"Annotated Image\")\n",
    "            plt.imshow(cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB))\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "        # Check if the largest blue rectangle covers more than 20% of the image\n",
    "        if largest_area / image_area > detection_threshold:\n",
    "            return True, largest_center_x\n",
    "\n",
    "        return False, largest_center_x\n",
    "  \n",
    "\n",
    "    def mask_qr_code_blue_filtered(self, image, margin_x=0, margin_y=0, debug=False, area_threshold=10):\n",
    "        # image to HSV color space\n",
    "        hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        # Define the range of blue in HSV --> assume we can use\n",
    "        low_blue = np.array([90, 100, 50])  \n",
    "        up_blue = np.array([150, 255, 255])\n",
    "\n",
    "        # Create a mask for blue regions\n",
    "        blue_mask = cv2.inRange(hsv_image, low_blue, up_blue)\n",
    "\n",
    "        # Find contours in the blue mask\n",
    "        contours, _= cv2.findContours(blue_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Filter contours based on area\n",
    "        filtered_contours = [c for c in contours if cv2.contourArea(c) > area_threshold]\n",
    "\n",
    "        if filtered_contours:\n",
    "            # Initialize the values for detecting min and max in the coordinate system\n",
    "            x_min = float('inf')\n",
    "            y_min = float('inf')\n",
    "            x_max = 0\n",
    "            y_max = 0\n",
    "\n",
    "            # Loop through all filtered contours to find the overall bounding box\n",
    "            for contour in filtered_contours:\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                x_min = min(x_min, x)\n",
    "                y_min = min(y_min, y)\n",
    "                x_max = max(x_max, x + w)\n",
    "                y_max = max(y_max, y + h)\n",
    "\n",
    "            # Add margins based on margin in x and y direction\n",
    "            x_min = max(x_min - margin_x, 0)\n",
    "            y_min = max(y_min - margin_y, 0)\n",
    "            x_max = min(x_max + margin_x, image.shape[1])\n",
    "            y_max = min(y_max + margin_y, image.shape[0])\n",
    "\n",
    "            if debug:\n",
    "                print(f\"Bounding Rectangle: x_min={x_min}, y_min={y_min}, x_max={x_max}, y_max={y_max}\")\n",
    "            \n",
    "            # Mask the rectangular region\n",
    "            processed_image = image.copy()\n",
    "            processed_image[y_min:y_max, x_min:x_max] = (255, 255, 255)  # White rectangle\n",
    "        else:\n",
    "            # If no contours remain after filtering, return the original image\n",
    "            processed_image = image.copy()\n",
    "\n",
    "        if debug:  # Debugging visualization\n",
    "            plt.figure(figsize=(20, 5))  # 4 subplots\n",
    "\n",
    "            # Original image\n",
    "            plt.subplot(1, 4, 1)\n",
    "            plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "            plt.title('Original Image')\n",
    "\n",
    "            # Blue mask\n",
    "            plt.subplot(1, 4, 2)\n",
    "            plt.imshow(blue_mask, cmap='gray')\n",
    "            plt.title('Blue Mask')\n",
    "\n",
    "            # Debug filtered contours\n",
    "            if filtered_contours:\n",
    "                debug_image = image.copy()\n",
    "                cv2.drawContours(debug_image, filtered_contours, -1, (0, 255, 0), 2)\n",
    "                plt.subplot(1, 4, 3)  # Update to match 4 subplots\n",
    "                plt.imshow(cv2.cvtColor(debug_image, cv2.COLOR_BGR2RGB))\n",
    "                plt.title('Filtered Contours and Rectangle')\n",
    "\n",
    "            # Processed image with masked region\n",
    "            plt.subplot(1, 4, 4)\n",
    "            plt.imshow(cv2.cvtColor(processed_image, cv2.COLOR_BGR2RGB))\n",
    "            plt.title('Processed Image (Blue Region Masked with Margin)')\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        return processed_image\n",
    "\n",
    "        \n",
    "            \n",
    "      \n",
    "    \n",
    "            \n",
    "    def preprocess_image(self, image, mask_qr = False):\n",
    "        \n",
    "        #Mask the qr code region of the vehicle in front based on a blue qr code holder\n",
    "        if mask_qr:\n",
    "            masked_image = self.mask_qr_code_blue_filtered(image, margin_x= 5 ,margin_y= 30, debug=False)\n",
    "            gray = cv2.cvtColor(masked_image, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            # Convert to grayscale\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Apply Gaussian blur to reduce noise\n",
    "        blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "        # Apply threshold to get binary image --> threshold needs to be goog enought for big road\n",
    "        _, binary = cv2.threshold(blurred, 106, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "        \n",
    "        #define region of interest for line detection, \n",
    "        roi_height = self.image_height // 2\n",
    "        #define new imgae to work with\n",
    "        roi = binary[roi_height:, :]\n",
    "\n",
    "        # Find connected components to later reduce noice in the image\n",
    "        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(roi, connectivity=8)\n",
    "\n",
    "        # Get areas of all components\n",
    "        areas = stats[1:, cv2.CC_STAT_AREA]  # Skip background just white pixels from binary image\n",
    "        road = \"small\" #init road detection\n",
    "        if len(areas) > 0:\n",
    "            # Calculate mean and median of component areas\n",
    "            mean_area = np.mean(areas)\n",
    "            median_area = np.median(areas)\n",
    "            # Dynamically set minimum area threshold\n",
    "            # If there are large components (like in the narrow road case),\n",
    "            # set a higher threshold relative to the mean area\n",
    "            if mean_area > 70:  # Threshold between small and big road --> big arround 50\n",
    "                #print(f\"small road: {mean_area}\")\n",
    "                road = \"small\"\n",
    "                min_area = mean_area * 0.8  # Remove components smaller than 60% of mean\n",
    "                filtered_binary = np.zeros_like(roi)\n",
    "                # Apply the adaptive threshold and filter out smaller ones\n",
    "                for label in range(1, num_labels):\n",
    "                    area = stats[label, cv2.CC_STAT_AREA]\n",
    "                    if area >= min_area:\n",
    "                        #print(f\"added part with area: {area} \")\n",
    "                        filtered_binary[labels == label] = 255 #\n",
    "\n",
    "                #apply filter with kernel size of 3x3 pixel\n",
    "                kernel = np.ones((3,3), np.uint8)\n",
    "                filtered_binary = cv2.morphologyEx(filtered_binary, cv2.MORPH_CLOSE, kernel)\n",
    "                filtered_binary = cv2.morphologyEx(filtered_binary, cv2.MORPH_OPEN, kernel)\n",
    "            else:\n",
    "                #print(f\"big road: {mean_area}\")\n",
    "                road = \"big\"\n",
    "                # For cases with smaller components (big road),\n",
    "                #static threshold works fine in here\n",
    "                min_area = 5  # Minimum baseline threshold\n",
    "                filtered_binary = roi  # If no components found, use original binary image           \n",
    "        else:\n",
    "            print(\"no components found\")\n",
    "            filtered_binary = roi  # If no components found, use original binary image\n",
    "\n",
    "        return gray, blurred, filtered_binary, binary, road\n",
    "        \n",
    "        \n",
    "    def detect_lines(self, binary_image, road):\n",
    "        roi_height = 112\n",
    "        roi = binary_image\n",
    "        #did this already before\n",
    "        #roi = binary_image[roi_height:, :]\n",
    "\n",
    "        # canny edge detector --> right now not needed\n",
    "        # edges = cv2.Canny(roi, 50, 150)\n",
    "        if road == \"small\":\n",
    "            #print(\"small road hough\")\n",
    "            lines = cv2.HoughLinesP(\n",
    "                roi,\n",
    "                rho=1,\n",
    "                theta=np.pi/180,\n",
    "                threshold=30,\n",
    "                minLineLength=40,\n",
    "                maxLineGap=30\n",
    "            )\n",
    "        else:\n",
    "            #print(\"big road hough\")\n",
    "            lines = cv2.HoughLinesP(\n",
    "                    roi,\n",
    "                    rho=1,\n",
    "                    theta=np.pi/180,\n",
    "                    threshold=20,\n",
    "                    minLineLength=30,\n",
    "                    maxLineGap=50\n",
    "                )  \n",
    "        left_lines = []\n",
    "        right_lines = []\n",
    "\n",
    "        if lines is not None:\n",
    "            for line in lines:\n",
    "                x1, y1, x2, y2 = line[0]\n",
    "                if x2 - x1 == 0:\n",
    "                    continue\n",
    "                slope = (y2 - y1) / (x2 - x1)\n",
    "\n",
    "                # find out which line it is left or right based on slope and position \n",
    "                line_center_x = (x1 + x2) / 2\n",
    "                if slope < 0 and line_center_x < self.image_width/2:  # Left line\n",
    "                    left_lines.append(line[0])\n",
    "                elif slope > 0 and line_center_x > self.image_width/2:  # Right line\n",
    "                    right_lines.append(line[0])\n",
    "\n",
    "        return left_lines, right_lines, roi_height, roi\n",
    "    \n",
    "    \n",
    "\n",
    "    def calculate_steering_angle(self, left_lines, right_lines, roi_height, road):\n",
    "        \"\"\"\n",
    "        Calculate steering angle based on available lines\n",
    "        \"\"\"\n",
    "        image_center = self.image_width // 2\n",
    "\n",
    "        # Initialize previous_steering_angle if it doesn't exist\n",
    "        if not hasattr(self, 'previous_steering_angle'):\n",
    "            self.previous_steering_angle = 0\n",
    "\n",
    "        # If no lines detected, maintain previous steering\n",
    "        if not left_lines and not right_lines:\n",
    "            return self.previous_steering_angle, image_center, image_center, 0, None\n",
    "\n",
    "        # If both lines are detected, use the original two-line method\n",
    "        if left_lines and right_lines:\n",
    "            #print(\"Mode 2 lines detected\")\n",
    "            # Get bottom points\n",
    "            left_bottom = self.get_bottom_point(left_lines)\n",
    "            right_bottom = self.get_bottom_point(right_lines)\n",
    "            \n",
    "            if left_bottom is None or right_bottom is None:\n",
    "                \n",
    "                return self.previous_steering_angle, image_center, image_center, 0, None\n",
    "            \n",
    "            # Calculate position deviation\n",
    "            left_x = left_bottom[0]\n",
    "            right_x = right_bottom[0]\n",
    "            center_x = (left_x + right_x) // 2\n",
    "            deviation = center_x - image_center\n",
    "            \n",
    "            # Calculate angle between bottom points\n",
    "            dx = right_bottom[0] - left_bottom[0]\n",
    "            dy = right_bottom[1] - left_bottom[1]\n",
    "            angle = np.arctan2(dy, dx) * 180 / np.pi\n",
    "            #print(\"test11113\")\n",
    "            # Combine position and angle for steering\n",
    "            position_weight = 0.5\n",
    "            angle_weight = 0.5\n",
    "            max_angle = 30\n",
    "            \n",
    "            #position deviation from the center\n",
    "            position_factor = deviation / (self.image_width / 2)\n",
    "            #print(f\"position_factor  is : {position_factor}\")\n",
    "            angle_factor = angle / 30\n",
    "            #print(f\"angle_factor is : {angle_factor}\")\n",
    "            # get final steering based on position offset and angle \n",
    "            steering_angle = -(position_weight * position_factor + angle_weight * angle_factor) * max_angle\n",
    "            #print(f\"steering_angle is : {steering_angle}\")\n",
    "            bottom_points = {\n",
    "                'left': (left_bottom[0], left_bottom[1] + roi_height),\n",
    "                'right': (right_bottom[0], right_bottom[1] + roi_height),\n",
    "                'angle': angle,\n",
    "                'single_line': False\n",
    "            }\n",
    "            bottom_point = (0, 0) \n",
    "\n",
    "        else:  # Single line case\n",
    "            # get the right line values \n",
    "            active_lines = left_lines if left_lines else right_lines\n",
    "            #which line is used as bool\n",
    "            using_right_line = bool(right_lines)\n",
    "\n",
    "            # Get bottom and top points of the line\n",
    "            bottom_point = self.get_bottom_point(active_lines)\n",
    "            top_point = self.get_top_point(active_lines)\n",
    "\n",
    "            if bottom_point is None or top_point is None:\n",
    "                print(\"Mode noline previous steering\")\n",
    "                return self.previous_steering_angle, image_center, image_center, 0, None\n",
    "\n",
    "            # Calculate angle relative to vertical\n",
    "            dx = top_point[0] - bottom_point[0]\n",
    "            dy = top_point[1] - bottom_point[1]\n",
    "            angle = np.arctan2(dx, dy) * 180 / np.pi  # Angle relative to vertical\n",
    "\n",
    "            # Calculate horizontal distance from image center to bottom point\n",
    "            distance_to_center = abs(bottom_point[0] - image_center)\n",
    "            max_distance = self.image_width / 2  # Maximum possible distance\n",
    "\n",
    "            # Calculate vertical position factor --> because bottom point can be also change just vertical afer a certain hor. offset\n",
    "            max_vertical = self.image_height/4  # maximum y-value in ROI    \n",
    "            #print(f\"positions top 0: {top_point[0]:.2f}\")\n",
    "            #print(f\"positions top 1: {top_point[1]:.2f}\")\n",
    "            #print(f\"positions bottom 0: {bottom_point[0]:.2f}\")\n",
    "            #print(f\"positions bottom 1: {bottom_point[1]:.2f}\")\n",
    "            # get vertical offset to bottom point, --> on the bottom = 0\n",
    "            vertical_position = (self.image_height/2) - bottom_point[1]  #distance from bottom to line in y\n",
    "            vertical_factor = vertical_position / max_vertical  # 0 when at bottom, 1 when in the middle or higher\n",
    "            distance_factor = 0\n",
    "            # Calculate the target angle in steps based on horzonatl distance or vertical offset:\n",
    "            if using_right_line:\n",
    "                #print(\"Mode right line detected\")\n",
    "                if vertical_factor > 0.1:\n",
    "                    # When line is not at bottom, prioritize vertical alignment\n",
    "                    # Target goes from -120° (vertical_factor=1) to -145° (vertical_factor=0)\n",
    "                    target_angle = -120 - (25 * (1 - vertical_factor))\n",
    "                else:\n",
    "                    # When line is at bottom, use horizontal distance\n",
    "                    # Target goes from -145° (distance_factor=1) to -190° (horizonatl distance_factor=0)\n",
    "                    distance_factor = distance_to_center / max_distance\n",
    "                    target_angle = -190 + (45 * distance_factor)\n",
    "            else:\n",
    "                #print(\"Mode left line detected\")\n",
    "                if vertical_factor > 0.1:\n",
    "                    # When line is not at bottom, prioritize vertical alignment\n",
    "                    # Target goes from 120° (vertical_factor=1) to 145° (vertical_factor=0)\n",
    "                    target_angle = 120 + (25 * (1 - vertical_factor))\n",
    "                else:\n",
    "                    # When line is at bottom, use horizontal distance\n",
    "                    # Target goes from 145° (distance_factor=1) to 190° (distance_factor=0)\n",
    "                    distance_factor = distance_to_center / max_distance\n",
    "                    target_angle = 190 - (45 * distance_factor)\n",
    "\n",
    "            #print(f\"Distance to center: {distance_to_center:.2f}\")\n",
    "            #print(f\"Vertical position: {vertical_position:.2f}\")\n",
    "            #print(f\"Vertical factor: {vertical_factor:.2f}\")\n",
    "            #print(f\"distance factor: {distance_factor:.2f}\")\n",
    "            #print(f\"Target angle: {target_angle:.1f}\")\n",
    "\n",
    "            steering_angle = -(angle - target_angle)\n",
    "            steering_angle *= 0.5  # Proportional gain\n",
    "\n",
    "            # Limit steering angle\n",
    "            max_angle = 30\n",
    "            steering_angle = np.clip(steering_angle, -max_angle, max_angle)\n",
    "\n",
    "            # Calculate deviation for visualization\n",
    "            deviation = bottom_point[0] - image_center\n",
    "\n",
    "            bottom_points = {\n",
    "                'single_line': True,\n",
    "                'line_angle': angle,\n",
    "                'bottom_point': (bottom_point[0], bottom_point[1] + roi_height),\n",
    "                'top_point': (top_point[0], top_point[1] + roi_height),\n",
    "                'using_right_line': using_right_line,\n",
    "                'target_angle': target_angle,\n",
    "                'distance_factor': distance_factor,\n",
    "                'distance_to_center': distance_to_center,\n",
    "                'vertical_factor': vertical_factor,\n",
    "                'vertical_position': vertical_position\n",
    "            }\n",
    "\n",
    "        self.previous_steering_angle = steering_angle\n",
    "        return steering_angle, bottom_point[0], image_center, deviation, bottom_points\n",
    "\n",
    "    def get_bottom_point(self, lines):\n",
    "        \"\"\"Find the point with maximum y value (bottom-most point)\"\"\"\n",
    "        max_y = -float('inf')\n",
    "        bottom_point = None\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line\n",
    "            if y1 > max_y:\n",
    "                max_y = y1\n",
    "                bottom_point = (x1, y1)\n",
    "            if y2 > max_y:\n",
    "                max_y = y2\n",
    "                bottom_point = (x2, y2)\n",
    "        return bottom_point\n",
    "\n",
    "    def get_top_point(self, lines):\n",
    "        \"\"\"Find the point with minimum y value (top-most point)\"\"\"\n",
    "        min_y = float('inf')\n",
    "        top_point = None\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line\n",
    "            if y1 < min_y:\n",
    "                min_y = y1\n",
    "                top_point = (x1, y1)\n",
    "            if y2 < min_y:\n",
    "                min_y = y2\n",
    "                top_point = (x2, y2)\n",
    "        return top_point\n",
    "\n",
    "        \n",
    "    def save_images(self, original, standard, probabilistic, timestamp, steering_angle):\n",
    "        # Save original image\n",
    "        cv2.imwrite(\n",
    "            os.path.join(self.save_dir, 'original', f'frame_{timestamp}.jpg'),\n",
    "            original\n",
    "        )\n",
    "        \n",
    "        # Save processed images (Roi image and the image wiht the detected lines in there)\n",
    "        cv2.imwrite(\n",
    "            os.path.join(self.save_dir, 'processed', f'frame_{timestamp}_ROI.jpg'),\n",
    "            standard\n",
    "        )\n",
    "        \n",
    "        cv2.imwrite(\n",
    "            os.path.join(self.save_dir, 'processed', f'frame_{timestamp}_FinalDetection.jpg'),\n",
    "            probabilistic\n",
    "        )\n",
    "        \n",
    "\n",
    "        \n",
    "    def process_frame(self, mask_qr = False):\n",
    "        # function to process the whole image\n",
    "        # Capture image\n",
    "        image = self.camera.value\n",
    "\n",
    "        # Preprocess image with open cv functions and thresholds\n",
    "        gray, blurred, binary, binary_init, road = self.preprocess_image(image, mask_qr = mask_qr)\n",
    "\n",
    "        # Detect lines\n",
    "        left_lines, right_lines, roi_height, roi = self.detect_lines(binary, road)\n",
    "        #print(\"test11\")\n",
    "        steering_angle, center_x, image_center, deviation, bottom_points = self.calculate_steering_angle(\n",
    "        left_lines, right_lines, roi_height, road)\n",
    "     \n",
    "\n",
    "        # copy image for drawing visualizations in there\n",
    "        visualization = image.copy()\n",
    "\n",
    "        if left_lines or right_lines:\n",
    "            # Draw all detected lines\n",
    "            # Draw left lines in blue\n",
    "            for line in left_lines:\n",
    "                x1, y1, x2, y2 = line\n",
    "                cv2.line(visualization, \n",
    "                        (x1, y1 + roi_height), \n",
    "                        (x2, y2 + roi_height), \n",
    "                        (255, 0, 0), 2)  # Blue color\n",
    "\n",
    "            # Draw right lines in red\n",
    "            for line in right_lines:\n",
    "                x1, y1, x2, y2 = line\n",
    "                cv2.line(visualization, \n",
    "                        (x1, y1 + roi_height), \n",
    "                        (x2, y2 + roi_height), \n",
    "                        (0, 0, 255), 2)  # Red color\n",
    "\n",
    "            if bottom_points:\n",
    "                bottom_y = self.image_height - 20  # Define bottom_y here for all cases\n",
    "\n",
    "                if bottom_points.get('single_line', False):\n",
    "                    # Single line visualization\n",
    "                    # Draw bottom and top points\n",
    "                    bottom = bottom_points['bottom_point']\n",
    "                    top = bottom_points['top_point']\n",
    "\n",
    "                    cv2.circle(visualization, bottom, 5, (255, 255, 0), -1)  # Yellow\n",
    "                    cv2.circle(visualization, top, 5, (255, 255, 0), -1)  # Yellow\n",
    "\n",
    "                    # Draw line between top and bottom points\n",
    "                    cv2.line(visualization,\n",
    "                            bottom,\n",
    "                            top,\n",
    "                            (0, 255, 255), 2)  # Yellow\n",
    "\n",
    "                    # Draw vertical reference line\n",
    "                    cv2.line(visualization,\n",
    "                            (image_center, bottom[1]),\n",
    "                            (image_center, top[1]),\n",
    "                            (0, 255, 0), 1)  # Green line\n",
    "\n",
    "                    # Add text for single line mode\n",
    "                    cv2.putText(visualization,\n",
    "                               f\"Mode: {'Right' if bottom_points['using_right_line'] else 'Left'} Line Only\",\n",
    "                               (10, bottom_y - 175),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                               0.5,\n",
    "                               (255, 255, 255),\n",
    "                               1)\n",
    "                    # Add visualization for adaptive target angle\n",
    "                    if 'target_angle' in bottom_points:\n",
    "                        # Draw current line angle\n",
    "                        #cv2.putText(visualization,\n",
    "                        #           f\"Current Angle: {bottom_points['line_angle']:.1f}°\",\n",
    "                        #           (10, bottom_y - 105),\n",
    "                        #           cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        #           0.5,\n",
    "                        #           (255, 255, 255),\n",
    "                        #           1)\n",
    "\n",
    "                        # Draw target angle\n",
    "                        cv2.putText(visualization,\n",
    "                                   f\"Target Angle: {bottom_points['target_angle']:.1f}°\",\n",
    "                                   (10, bottom_y - 150),\n",
    "                                   cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                   0.5,\n",
    "                                   (255, 255, 255),\n",
    "                                   1)\n",
    "\n",
    "                        # In the visualization part:\n",
    "                        # Draw target angle line\n",
    "                        arrow_length = 40\n",
    "                        target_angle_rad = np.radians(bottom_points['target_angle'])\n",
    "                        target_x = int(arrow_length * np.sin(target_angle_rad))\n",
    "                        target_y = int(arrow_length * np.cos(target_angle_rad))\n",
    "\n",
    "                        cv2.line(visualization,\n",
    "                                (image_center, bottom_y - 60),\n",
    "                                (image_center + target_x, bottom_y - 60 - target_y),\n",
    "                                (0, 255, 0),  # Green color for target\n",
    "                                1)\n",
    "                else:\n",
    "                    # Dual line visualization\n",
    "                    cv2.circle(visualization, bottom_points['left'], 5, (255, 255, 0), -1)  # Yellow\n",
    "                    cv2.circle(visualization, bottom_points['right'], 5, (255, 255, 0), -1)  # Yellow\n",
    "                    cv2.putText(visualization,\n",
    "                               \"Mode: 2 lines detected\",\n",
    "                               (10, bottom_y - 150),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                               0.5,\n",
    "                               (255, 255, 255),\n",
    "                               1)\n",
    "\n",
    "                    # Draw line between bottom points\n",
    "                    cv2.line(visualization,\n",
    "                            bottom_points['left'],\n",
    "                            bottom_points['right'],\n",
    "                            (0, 255, 255), 2)  # Yellow\n",
    "\n",
    "                    # Draw horizontal reference line\n",
    "                    mid_y = (bottom_points['left'][1] + bottom_points['right'][1]) // 2\n",
    "                    left_x = min(bottom_points['left'][0], bottom_points['right'][0])\n",
    "                    right_x = max(bottom_points['left'][0], bottom_points['right'][0])\n",
    "                    cv2.line(visualization,\n",
    "                        (left_x, mid_y),\n",
    "                        (right_x, mid_y),\n",
    "                        (0, 255, 0), 1)  # Green line\n",
    "\n",
    "                # Draw correction visualization (common for both modes)\n",
    "                # Draw image center line\n",
    "                cv2.line(visualization,\n",
    "                        (image_center, bottom_y - 40),\n",
    "                        (image_center, bottom_y),\n",
    "                        (255, 255, 0), 2)\n",
    "\n",
    "                # Draw detected center point\n",
    "                cv2.line(visualization,\n",
    "                        (center_x, bottom_y - 40),\n",
    "                        (center_x, bottom_y),\n",
    "                        (0, 255, 0), 2)\n",
    "\n",
    "                # Draw deviation line\n",
    "                cv2.line(visualization,\n",
    "                        (image_center, bottom_y - 20),\n",
    "                        (center_x, bottom_y - 20),\n",
    "                        (255, 0, 255), 2)\n",
    "\n",
    "\n",
    "                angle_value = bottom_points.get('line_angle' if bottom_points.get('single_line', False) else 'angle', 0)\n",
    "                cv2.putText(visualization,\n",
    "                           f\"Angle: {angle_value:.1f} deg\",\n",
    "                           (10, bottom_y - 125),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                           0.5,\n",
    "                           (255, 255, 255),\n",
    "                           1)\n",
    "\n",
    "                cv2.putText(visualization,\n",
    "                           f\"Steering: {steering_angle:.1f} deg\",\n",
    "                           (10, bottom_y - 100),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                           0.5,\n",
    "                           (255, 255, 255),\n",
    "                           1)\n",
    "                \n",
    "                # Save images--> only debug do not use during normal run, takes too much performance\n",
    "                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S_%f')\n",
    "                self.save_images(image, binary, visualization, \n",
    "                            timestamp, steering_angle)\n",
    "\n",
    "                \n",
    "\n",
    "        return steering_angle, {\n",
    "            'original': cv2.cvtColor(image, cv2.COLOR_BGR2RGB),\n",
    "            'grayscale': gray,\n",
    "            'blurred': blurred,\n",
    "            'binary': binary_init,\n",
    "            'roi': roi,\n",
    "            'result': cv2.cvtColor(visualization, cv2.COLOR_BGR2RGB)\n",
    "        }\n",
    "    def stop(self):\n",
    "        self.camera.stop()\n",
    "\n",
    "def plot_processing_steps(images, steering_angle):\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    fig.suptitle(f'Line Detection Processing Steps (Steering Angle: {steering_angle:.2f}°)', fontsize=16)\n",
    "    \n",
    "    # Plot original image\n",
    "    axes[0, 0].imshow(images['original'])\n",
    "    axes[0, 0].set_title('Original Image')\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    # Plot grayscale image\n",
    "    axes[0, 1].imshow(images['grayscale'], cmap='gray')\n",
    "    axes[0, 1].set_title('Grayscale')\n",
    "    axes[0, 1].axis('off')\n",
    "    \n",
    "    # Plot blurred image\n",
    "    axes[0, 2].imshow(images['blurred'], cmap='gray')\n",
    "    axes[0, 2].set_title('Gaussian Blur')\n",
    "    axes[0, 2].axis('off')\n",
    "    \n",
    "    # Plot binary image\n",
    "    axes[1, 0].imshow(images['binary'], cmap='gray')\n",
    "    axes[1, 0].set_title('Binary Threshold')\n",
    "    axes[1, 0].axis('off')\n",
    "    \n",
    "    # Plot ROI\n",
    "    axes[1, 1].imshow(images['roi'], cmap='gray')\n",
    "    axes[1, 1].set_title('Region of Interest')\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    # Plot final result with detected lines\n",
    "    axes[1, 2].imshow(images['result'])\n",
    "    axes[1, 2].set_title('Detected Lines')\n",
    "    axes[1, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genuine-service",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-reflection",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-completion",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PIDController:\n",
    "    def __init__(self, kp, ki, kd):\n",
    "        self.kp = kp # proportinal facorte\n",
    "        self.ki = ki # integral part\n",
    "        self.kd = kd # damping part\n",
    "        \n",
    "        self.previous_error = 0\n",
    "        self.integral = 0\n",
    "        \n",
    "    def compute(self, error, dt):\n",
    "        \"\"\"\n",
    "        calcualte pid values from error \n",
    "        \"\"\"\n",
    "        # Proportional term\n",
    "        p_term = self.kp * error\n",
    "        \n",
    "        # Integral term\n",
    "        self.integral += error * dt\n",
    "        i_term = self.ki * self.integral\n",
    "        \n",
    "        # Derivative term\n",
    "        derivative = (error - self.previous_error) / dt\n",
    "        d_term = self.kd * derivative\n",
    "        \n",
    "        # Save error for next iteration\n",
    "        self.previous_error = error\n",
    "        \n",
    "        # Compute total control value\n",
    "        control = p_term + i_term + d_term\n",
    "        \n",
    "        return control\n",
    "        \n",
    "    def reset(self):\n",
    "        \"\"\"Reset the PID controller\"\"\"\n",
    "        self.previous_error = 0\n",
    "        self.integral = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elect-revelation",
   "metadata": {},
   "outputs": [],
   "source": [
    " from IPython.display import clear_output\n",
    "class LineFollower:\n",
    "    def __init__(self, robot, camera, base_speed=0.4):\n",
    "        # Initialize robot and camera\n",
    "        #self.robot = Robot() # robot init comes from outside\n",
    "        #self.camera = Camera.instance(width=224, height=224) # camera init comes from outside\n",
    "        self.robot = robot\n",
    "        self.camera = camera\n",
    "        self.detector = LineDetector(camera = self.camera)\n",
    "        \n",
    "        # PID controller for steering\n",
    "        self.pid = PIDController(kp=0.015, ki=0.0005, kd=0.004)\n",
    "        \n",
    "        # Motor control parameters\n",
    "        self.base_speed = base_speed\n",
    "        self.max_steering = 0.3  # Maximum steering adjustment --> has to be connected with the decided max speed\n",
    "        \n",
    "        # Time information for PID\n",
    "        self.previous_time = time.time()\n",
    "        \n",
    "    def steer(self, steering_value, speed):\n",
    "        \"\"\"\n",
    "        Convert steering value to motor commands\n",
    "        steering commands are normally between 0 and 1 for the left and the right motor\n",
    "        \"\"\"\n",
    "        # Clip steering value\n",
    "        steering_value = np.clip(steering_value, -1, 1)\n",
    "        \n",
    "        # Calculate motor values\n",
    "        if steering_value >= 0:\n",
    "            # Turning right\n",
    "            left_speed = speed\n",
    "            right_speed = speed * (1 - steering_value)\n",
    "        else:\n",
    "            # Turning left\n",
    "            left_speed = speed * (1 + steering_value)\n",
    "            right_speed = speed\n",
    "            \n",
    "        #print(f\"Left speed: {left_speed}\")\n",
    "        #print(f\"Right speed: {right_speed}\")\n",
    "        # Apply motor values\n",
    "        self.robot.left_motor.value = float(left_speed)\n",
    "        self.robot.right_motor.value = float(right_speed)\n",
    "        \n",
    "    def follow_line_loop(self,mask_qr=False):\n",
    "        \"\"\"Main line follower loop\"\"\"\n",
    "        try:\n",
    "            iterrations = 0\n",
    "            while True:\n",
    "                # Calculate time for one loop iteration\n",
    "                \n",
    "                current_time = time.time()\n",
    "                dt = current_time - self.previous_time\n",
    "                #print(f\"Time betwwen calls: {(dt*1000)} ms\")\n",
    "                self.previous_time = current_time\n",
    "                \n",
    "                # Get steering angle from your existing line detection code\n",
    "                steering_angle, images = self.detector.process_frame(mask_qr=mask_qr)\n",
    "                \n",
    "                #print(\"test1\")\n",
    "                clear_output(wait=True)\n",
    "                plot_processing_steps(images, steering_angle)\n",
    "                #steering_angle, visualization = self.process_frame()  # Your existing method\n",
    "                print(f\"steering angle: {steering_angle}\")\n",
    "                # Convert steering angle to normalized error (-1 to 1)\n",
    "                error = steering_angle / 30.0  # Assuming max steering angle is 30 degrees\n",
    "                #print(f\"error : {error}\")\n",
    "                # Compute PID control value\n",
    "                if (iterrations > 5):\n",
    "                    control_value = self.pid.compute(steering_angle, dt)\n",
    "                    #print(f\"controller : {control_value}\")\n",
    "                    # Apply steering\n",
    "                    self.steer(control_value, self.base_speed)\n",
    "                    time.sleep(0.2)# set sleep timer to simulate not realtime execution\n",
    "                else:\n",
    "                    iterrations = iterrations +1 \n",
    "                #if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                 #   break\n",
    "                \n",
    "                \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Stopping robot...\")\n",
    "        finally:\n",
    "            # Stop the robot\n",
    "            self.robot.stop()\n",
    "            cv2.destroyAllWindows()\n",
    "            self.camera.stop()\n",
    "            \n",
    "    def follow_line_single(self, speed, start_motion, mask_qr=False, follow_blue_rect=True):\n",
    "        \"\"\"Main line follower loop\"\"\"\n",
    "        try:\n",
    "            iterrations = 0\n",
    "            \n",
    "            # Calculate time for one loop iteration\n",
    "\n",
    "            current_time = time.time()\n",
    "            dt = current_time - self.previous_time\n",
    "            #print(f\"Time betwwen calls: {(dt*1000)} ms\")\n",
    "            self.previous_time = current_time\n",
    "\n",
    "            # Get steering angle from your existing line detection code\n",
    "            steering_angle, images = self.detector.process_frame(mask_qr=mask_qr)\n",
    "            \n",
    "            if follow_blue_rect:\n",
    "                blue_rect_detected, center_point = self.detector.detect_large_blue_rectangle()\n",
    "                if blue_rect_detected and 48 < center_point < 176:\n",
    "                    steering_angle = -30 + (center_point - 48) * 60 / (176 - 48)\n",
    "\n",
    "            #print(\"test1\")\n",
    "            #clear_output(wait=True)\n",
    "            #plot_processing_steps(images, steering_angle)\n",
    "            #steering_angle, visualization = self.process_frame()  # Your existing method\n",
    "            #print(f\"steering angle: {steering_angle}\")\n",
    "            # Convert steering angle to normalized error (-1 to 1)\n",
    "            error = steering_angle / 30.0  # Assuming max steering angle is 30 degrees\n",
    "            #print(f\"error : {error}\")\n",
    "            # Compute PID control value\n",
    "            if start_motion == True:\n",
    "                control_value = self.pid.compute(steering_angle, dt)\n",
    "                #print(f\"controller : {control_value}\")\n",
    "                # Apply steering\n",
    "                self.steer(control_value, speed)\n",
    "            else:\n",
    "                self.robot.left_motor.value = 0.0\n",
    "                self.robot.right_motor.value = 0.0\n",
    "            #if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "             #   break\n",
    "            \n",
    "            return blue_rect_detected\n",
    "                \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Stopping robot...\")\n",
    "        \n",
    "            # Stop the robot\n",
    "            #self.robot.stop()\n",
    "            #cv2.destroyAllWindows()\n",
    "            #self.camera.stop()\n",
    "    \n",
    "    def stop(self):\n",
    "        \"\"\"Stop the robot\"\"\"\n",
    "        self.robot.left_motor.value = 0.0\n",
    "        self.robot.right_motor.value = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-thickness",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #comment in for debug\n",
    "    robot = Robot()\n",
    "    camera = Camera.instance (width=224, height=224)\n",
    "    follower = LineFollower(robot, camera,base_speed=0.25) \n",
    "    try:\n",
    "        print(\"Start\")\n",
    "        #Start line following\n",
    "        #follower.follow_line_loop(mask_qr=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    finally:\n",
    "        # Make sure robot stops\n",
    "        follower.stop()\n",
    "        camera.stop()\n",
    "        robot.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-tucson",
   "metadata": {},
   "outputs": [],
   "source": [
    "#camera.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-armor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#robot.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "requested-lambda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
